# ==================== LLM 配置 ====================
# LLM 提供商: openai | anthropic | deepseek | siliconflow
LLM_PROVIDER=deepseek

# ==================== LLM URL 配置 ====================
# 通用独立 URL（最高优先级，适用于所有提供商）
# LLM_BASE_URL_FIELD=https://custom-llm-api.com/v1
# 提供商特定 URL（中等优先级，仅适用于特定提供商）
# OPENAI_LLM_BASE_URL_FIELD=https://api.openai.com/v1
# DEEPSEEK_LLM_BASE_URL_FIELD=https://api.deepseek.com/v1
# SILICONFLOW_LLM_BASE_URL_FIELD=https://api.siliconflow.cn/v1
# ANTHROPIC_LLM_BASE_URL_FIELD=https://api.anthropic.com/v1
# 共享 URL（最低优先级，向后兼容）
# 如果未设置独立URL和提供商特定URL，将使用：
# - DeepSeek: DEEPSEEK_BASE_URL
# - SiliconFlow: SILICONFLOW_BASE_URL
# - OpenAI/Anthropic: 使用默认URL

# DeepSeek API 配置（默认）
DEEPSEEK_API_KEY=sk-your-deepseek-api-key
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
DEEPSEEK_MODEL=deepseek-chat

# OpenAI API 配置（可选）
# OPENAI_API_KEY=sk-your-openai-api-key
# OPENAI_LLM_BASE_URL_FIELD=https://api.openai.com/v1
# OPENAI_MODEL=gpt-4o-mini

# Anthropic API 配置（可选）
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key
# ANTHROPIC_LLM_BASE_URL_FIELD=https://api.anthropic.com/v1
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# 硅基流动 API 配置（可选）
# SILICONFLOW_API_KEY=your-siliconflow-api-key
# SILICONFLOW_BASE_URL=https://api.siliconflow.cn/v1
# SILICONFLOW_LLM_MODEL=Qwen/Qwen2.5-7B-Instruct

# ==================== Embedding 配置 ====================
# Embedding 模型: openai | deepseek | local | siliconflow
EMBEDDING_PROVIDER=deepseek
# ==================== Embedding API Key 配置 ====================
# 通用独立 API Key（最高优先级，适用于所有提供商）
# EMBEDDING_API_KEY_FIELD=sk-your-universal-embedding-key
# 提供商特定 API Key（中等优先级，仅适用于特定提供商）
# OPENAI_EMBEDDING_API_KEY=sk-your-openai-embedding-key
# DEEPSEEK_EMBEDDING_API_KEY=sk-your-deepseek-embedding-key
# SILICONFLOW_EMBEDDING_API_KEY=sk-your-siliconflow-embedding-key
# ANTHROPIC_EMBEDDING_API_KEY=sk-your-anthropic-embedding-key
# 共享 API Key（最低优先级，向后兼容）
# 如果未设置独立API Key和提供商特定API Key，将使用：
# - DeepSeek: DEEPSEEK_API_KEY
# - OpenAI: OPENAI_API_KEY
# - SiliconFlow: SILICONFLOW_API_KEY
# - Anthropic: ANTHROPIC_API_KEY
# ==================== Embedding URL 配置 ====================
# 通用独立 URL（最高优先级，适用于所有提供商）
# EMBEDDING_BASE_URL=https://custom-embedding-api.com/v1
#
# 提供商特定 URL（中等优先级，仅适用于特定提供商）
# OPENAI_EMBEDDING_BASE_URL=https://api.openai.com/v1
# DEEPSEEK_EMBEDDING_BASE_URL=https://embedding.deepseek.com/v1
# SILICONFLOW_EMBEDDING_BASE_URL=https://embedding.siliconflow.cn/v1
# ANTHROPIC_EMBEDDING_BASE_URL=https://api.anthropic.com/v1
#
# 共享 URL（最低优先级，向后兼容）
# 如果未设置独立URL和提供商特定URL，将使用：
# - DeepSeek: DEEPSEEK_BASE_URL
# - SiliconFlow: SILICONFLOW_BASE_URL
# - OpenAI/Anthropic: 使用默认URL
#

DEEPSEEK_EMBEDDING_API_KEY=sk-your-deepseek-embedding-key
DEEPSEEK_EMBEDDING_BASE_URL=https://embedding.deepseek.com/v1
EMBEDDING_MODEL=deepseek-embedding


# OpenAI Embedding（可选）
# OPENAI_EMBEDDING_API_KEY=sk-your-openai-embedding-key
# OPENAI_EMBEDDING_BASE_URL=https://api.openai.com/v1
# EMBEDDING_MODEL=text-embedding-ada-002


# 硅基流动 Embedding（可选）
# SILICONFLOW_EMBEDDING_API_KEY=sk-your-siliconflow-embedding-key
# SILICONFLOW_EMBEDDING_BASE_URL=https://embedding.siliconflow.cn/v1
# SILICONFLOW_EMBEDDING_MODEL=BAAI/bge-large-zh-v1.5

EMBEDDING_DIM=1536

# ==================== 模型别名配置 ====================
# 是否启用模型别名功能（⚠️警告：启用后将使用OpenAI品牌名称，存在商标风险）
MODEL_ALIAS_ENABLED=false
MODEL_ALIAS_NAME=gpt-4o-mini
MODEL_ALIAS_OWNED_BY=openai
HIDE_EMBEDDING_MODELS=true

# ==================== Milvus 配置 ====================
MILVUS_HOST=your-milvus-host
MILVUS_PORT=19530
MILVUS_USER=root
MILVUS_PASSWORD=
MILVUS_DATABASE=default

# Milvus Collection 名称
MILVUS_KNOWLEDGE_COLLECTION=knowledge_base
MILVUS_HISTORY_COLLECTION=conversation_history

# ==================== Redis 配置 ====================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# Redis 连接池
REDIS_MAX_CONNECTIONS=10

# ==================== API 配置 ====================
# API 认证密钥（必填）
API_KEY=your-secure-api-key-here

# CORS 配置（多个域名用逗号分隔）
CORS_ORIGINS=http://localhost:3000,https://your-wordpress-site.com

# ==================== 应用配置 ====================
# 日志级别: DEBUG | INFO | WARNING | ERROR
LOG_LEVEL=INFO

# 服务端口
PORT=8000

# ==================== LangGraph 配置 ====================
# Agent 最大迭代次数
LANGGRAPH_MAX_ITERATIONS=10

# Checkpointer 类型: memory | redis
LANGGRAPH_CHECKPOINTER=redis

# ==================== 向量召回配置 ====================
# 注意：RAG_* 配置项已迁移为 VECTOR_*，旧字段保留为别名
# 知识库检索 Top-K
VECTOR_TOP_K=3

# 相似度分数阈值（0-1）
VECTOR_SCORE_THRESHOLD=0.7

# 文档切片大小（tokens）
VECTOR_CHUNK_SIZE=500

# 文档切片重叠（tokens）
VECTOR_CHUNK_OVERLAP=50

# ==================== 性能配置 ====================
# LLM 温度参数
LLM_TEMPERATURE=0.7

# LLM 最大 Token 数
LLM_MAX_TOKENS=2000

# 缓存 TTL（秒）
CACHE_TTL=300


# ==================== 召回编排层配置 ====================
# 启用的召回源列表（逗号分隔）
RECALL_SOURCES=["vector"]

# 召回源权重配置（逗号分隔，格式: source:weight）
RECALL_SOURCE_WEIGHTS="vector:1.0"

# 召回超时时间（毫秒）
RECALL_TIMEOUT_MS=3000

# 召回失败重试次数
RECALL_RETRY=1

# 召回结果合并策略 (weighted/rrf/custom)
RECALL_MERGE_STRATEGY="weighted"

# 召回结果置信度降级阈值（0.0-1.0）
RECALL_DEGRADE_THRESHOLD=0.5

# 是否启用召回降级策略
RECALL_FALLBACK_ENABLED=True

# 是否启用召回实验
RECALL_EXPERIMENT_ENABLED=False

# 实验平台类型（None/internal/growthbook等）
RECALL_EXPERIMENT_PLATFORM=None

# ==================== 配置示例说明 ====================
# 
# 1. 基础配置分离示例（DeepSeek LLM + OpenAI Embedding）：
#    LLM_PROVIDER=deepseek
#    DEEPSEEK_API_KEY=sk-your-deepseek-key
#    DEEPSEEK_MODEL=deepseek-chat
#    EMBEDDING_PROVIDER=openai
#    OPENAI_API_KEY=sk-your-openai-key
#    EMBEDDING_MODEL=text-embedding-3-small
#
# 2. 硅基流动平台配置示例：
#    LLM_PROVIDER=siliconflow
#    SILICONFLOW_API_KEY=your-sf-key
#    SILICONFLOW_LLM_MODEL=Qwen/Qwen2.5-7B-Instruct
#    EMBEDDING_PROVIDER=siliconflow
#    SILICONFLOW_EMBEDDING_MODEL=BAAI/bge-large-zh-v1.5
#
# 3. 混合模型组合示例（OpenAI LLM + DeepSeek Embedding）：
#    LLM_PROVIDER=openai
#    OPENAI_API_KEY=sk-your-openai-key
#    OPENAI_MODEL=gpt-4o-mini
#    EMBEDDING_PROVIDER=deepseek
#    DEEPSEEK_API_KEY=sk-your-deepseek-key
#    EMBEDDING_MODEL=deepseek-embedding
#
# 更多配置说明请参考：
# - docs/configuration/model-separation.md
# - docs/architecture/plugin-system.md
# - docs/migration/legacy-to-plugin.md

# ==================== 消息过滤配置 ====================
# 启用消息过滤功能
MESSAGE_FILTER_ENABLED=true

# 消息最大长度（字符）
MESSAGE_MAX_LENGTH=1000

# 指令模板关键词（逗号分隔）
INSTRUCTION_KEYWORDS=You are an AI,Your role is to,Follow these guidelines,Use user's language,Always return,Always wrap,You are a helpful assistant,Your task is to,Please rephrase,Convert the following,Transform this query

# 技术术语阈值（超过此数量将被过滤）
TECHNICAL_TERMS_THRESHOLD=3

# 技术术语列表（逗号分隔）
TECHNICAL_TERMS=API,endpoint,function,method,parameter,response,request
