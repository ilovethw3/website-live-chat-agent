"""
LangGraph StateGraph æ„å»º

ç»„è£…æ‰€æœ‰èŠ‚ç‚¹å’Œè¾¹ï¼Œæ„å»ºå®Œæ•´çš„ Agent å·¥ä½œæµã€‚
"""

import logging

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, StateGraph

from src.agent.edges import should_continue, should_retrieve
from src.agent.nodes import call_llm_node, retrieve_node, router_node
from src.agent.state import AgentState
from src.core.config import settings

logger = logging.getLogger(__name__)


def create_agent_graph() -> StateGraph:
    """
    åˆ›å»º LangGraph Agent å·¥ä½œæµ

    å·¥ä½œæµç¨‹ï¼š
    1. START â†’ router â†’ åˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢
    2. éœ€è¦æ£€ç´¢ â†’ retrieve â†’ llm â†’ END
    3. ä¸éœ€è¦æ£€ç´¢ â†’ llm â†’ END

    Returns:
        ç¼–è¯‘åçš„ LangGraph App
    """
    logger.info("ğŸ”§ Building LangGraph StateGraph...")

    # åˆ›å»º StateGraph
    workflow = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("router", router_node)
    workflow.add_node("retrieve", retrieve_node)
    workflow.add_node("llm", call_llm_node)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("router")

    # æ·»åŠ æ¡ä»¶è¾¹: router â†’ retrieve æˆ– llm
    workflow.add_conditional_edges(
        "router",
        should_retrieve,
        {
            "retrieve": "retrieve",  # éœ€è¦æ£€ç´¢ â†’ æ£€ç´¢èŠ‚ç‚¹
            "llm": "llm"            # ä¸éœ€è¦æ£€ç´¢ â†’ ç›´æ¥ LLM
        }
    )

    # æ·»åŠ è¾¹: retrieve â†’ llm
    workflow.add_edge("retrieve", "llm")

    # æ·»åŠ æ¡ä»¶è¾¹: llm â†’ ENDï¼ˆå¯æ‰©å±•ä¸ºäººå·¥ä»‹å…¥ï¼‰
    workflow.add_conditional_edges(
        "llm",
        should_continue,
        {
            "END": END
        }
    )

    logger.info("âœ… StateGraph built successfully")
    return workflow


def compile_agent_graph() -> any:
    """
    ç¼–è¯‘ Agent Graph

    æ ¹æ®é…ç½®é€‰æ‹© Checkpointerï¼š
    - memory: MemorySaverï¼ˆå¼€å‘/æµ‹è¯•ï¼‰
    - redis: RedisSaverï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰

    Returns:
        ç¼–è¯‘åçš„ LangGraph App
    """
    workflow = create_agent_graph()

    # é€‰æ‹© Checkpointer
    if settings.langgraph_checkpointer == "memory":
        logger.info("ğŸ“ Using MemorySaver for checkpointing")
        checkpointer = MemorySaver()
    elif settings.langgraph_checkpointer == "redis":
        logger.info("ğŸ“ Using RedisSaver for checkpointing")
        try:
            import redis
            from langgraph.checkpoint.redis import RedisSaver

            redis_client = redis.Redis(
                host=settings.redis_host,
                port=settings.redis_port,
                password=settings.redis_password if settings.redis_password else None,
                db=settings.redis_db,
                decode_responses=False,  # RedisSaver éœ€è¦ bytes
            )

            checkpointer = RedisSaver(redis_client)
        except ImportError:
            logger.warning("âš ï¸ langgraph-checkpoint-redis not installed, falling back to MemorySaver")
            checkpointer = MemorySaver()
        except Exception as e:
            logger.error(f"âŒ Failed to create RedisSaver: {e}, falling back to MemorySaver")
            checkpointer = MemorySaver()
    else:
        logger.warning(f"âš ï¸ Unknown checkpointer: {settings.langgraph_checkpointer}, using MemorySaver")
        checkpointer = MemorySaver()

    # ç¼–è¯‘
    app = workflow.compile(checkpointer=checkpointer)

    logger.info("âœ… LangGraph App compiled successfully")
    return app


# å…¨å±€ Agent App å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
_agent_app = None


def get_agent_app() -> any:
    """
    è·å– Agent App å•ä¾‹

    Returns:
        ç¼–è¯‘åçš„ LangGraph App
    """
    global _agent_app
    if _agent_app is None:
        _agent_app = compile_agent_graph()
    return _agent_app


async def run_agent(
    user_message: str,
    session_id: str,
    chat_history: list | None = None
) -> dict:
    """
    æ‰§è¡Œ Agent æ¨ç†

    Args:
        user_message: ç”¨æˆ·æ¶ˆæ¯
        session_id: ä¼šè¯IDï¼ˆç”¨äº Checkpointerï¼‰
        chat_history: å†å²å¯¹è¯ï¼ˆå¯é€‰ï¼Œå¦‚æœä½¿ç”¨ Checkpointer åˆ™è‡ªåŠ¨åŠ è½½ï¼‰

    Returns:
        Agent å“åº”å’ŒçŠ¶æ€
    """
    from langchain_core.messages import HumanMessage

    app = get_agent_app()

    # æ„å»ºåˆå§‹çŠ¶æ€
    initial_state = {
        "messages": [HumanMessage(content=user_message)],
        "retrieved_docs": [],
        "tool_calls": [],
        "session_id": session_id,
        "next_step": None,
        "error": None,
        "confidence_score": None,
    }

    # é…ç½®ï¼ˆåŒ…å« session_id ç”¨äº Checkpointerï¼‰
    config = {"configurable": {"thread_id": session_id}}

    # æ‰§è¡Œ Agent
    try:
        result = await app.ainvoke(initial_state, config)
        logger.info(f"âœ… Agent execution completed for session {session_id}")
        return result
    except Exception as e:
        logger.error(f"âŒ Agent execution failed: {e}")
        raise


async def stream_agent(
    user_message: str,
    session_id: str,
) -> any:
    """
    æµå¼æ‰§è¡Œ Agentï¼ˆç”¨äº SSEï¼‰

    Args:
        user_message: ç”¨æˆ·æ¶ˆæ¯
        session_id: ä¼šè¯ID

    Yields:
        Agent æ‰§è¡Œè¿‡ç¨‹ä¸­çš„çŠ¶æ€æ›´æ–°
    """
    from langchain_core.messages import HumanMessage

    app = get_agent_app()

    initial_state = {
        "messages": [HumanMessage(content=user_message)],
        "retrieved_docs": [],
        "tool_calls": [],
        "session_id": session_id,
        "next_step": None,
        "error": None,
        "confidence_score": None,
    }

    config = {"configurable": {"thread_id": session_id}}

    try:
        async for chunk in app.astream(initial_state, config):
            logger.debug(f"ğŸ“¦ Agent chunk: {list(chunk.keys())}")
            yield chunk
    except Exception as e:
        logger.error(f"âŒ Agent streaming failed: {e}")
        raise

